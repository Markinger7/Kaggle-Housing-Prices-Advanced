{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "# ml related imports\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# silence settingWithCopyWarning\n",
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 81), (1459, 80))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test shape\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pre = train.copy()\n",
    "test_pre = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine data\n",
    "all_data = pd.concat([train_pre, test_pre], ignore_index=True)\n",
    "\n",
    "# a lot of the missing values are just encodings for the instance that a specific feaure isn't available\n",
    "# list of features with worng encodign for NA\n",
    "feature_NA = ['Alley', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence', \n",
    "              'MiscFeature', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']\n",
    "\n",
    "# assign NA to None to indicate the lack of a certain feature\n",
    "all_data[feature_NA] = all_data[feature_NA].fillna('None')\n",
    "\n",
    "# imute missing categorical features mostly with the mode\n",
    "all_data['MSZoning'] = all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])\n",
    "all_data['Utilities'] = all_data['Utilities'].fillna(all_data['Utilities'].mode()[0])\n",
    "all_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\n",
    "all_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\n",
    "all_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\n",
    "all_data['MasVnrType'] = all_data['MasVnrType'].fillna('None')\n",
    "all_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\n",
    "all_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\n",
    "all_data['Functional'] = all_data['Functional'].fillna(all_data['Functional'].mode()[0])\n",
    "all_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])\n",
    "\n",
    "# imput missing numerical features (most numercial had only 1-2 missing values in that case I just imputet 0)\n",
    "all_data['MasVnrArea'] = all_data['MasVnrArea'].fillna(0)\n",
    "all_data['BsmtFinSF1'] = all_data['BsmtFinSF1'].fillna(0)\n",
    "all_data['BsmtFinSF2'] = all_data['BsmtFinSF2'].fillna(0)\n",
    "all_data['BsmtUnfSF'] = all_data['BsmtUnfSF'].fillna(0)\n",
    "all_data['TotalBsmtSF'] = all_data['TotalBsmtSF'].fillna(0)\n",
    "all_data['BsmtFullBath'] = all_data['BsmtFullBath'].fillna(0)\n",
    "all_data['BsmtHalfBath'] = all_data['BsmtHalfBath'].fillna(0)\n",
    "all_data['GarageCars'] = all_data['GarageCars'].fillna(0)\n",
    "all_data['GarageArea'] = all_data['GarageArea'].fillna(0)\n",
    "all_data['GarageYrBlt'] = all_data['GarageYrBlt'].fillna(0)\n",
    "# Neighorhood should impact the size of of street connected to the property\n",
    "# code from https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard\n",
    "all_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n",
    "    lambda x: x.fillna(x.median()))\n",
    "\n",
    "# transform features into different types\n",
    "# MSSubClasee\n",
    "all_data['MSSubClass'] = all_data['MSSubClass'].astype('str')\n",
    "# month sold\n",
    "MoSold_dict = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', 7:'Jul', 8:'Aug', 9:'Sep', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
    "all_data['MoSold'] = all_data['MoSold'].map(MoSold_dict)\n",
    "\n",
    "# convert categorical to ordinal features \n",
    "ord_feats = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
    "             'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC']\n",
    "map_dict_ord = {'None': 0, 'Po': 1, 'Fa': 2, 'TA':3, 'Gd':4, 'Ex': 5, 'No': 1, 'Mn': 2, 'Av': 3, 'Unf': 1, \n",
    "                'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6}\n",
    "for ord_ in ord_feats:\n",
    "    all_data[ord_] = all_data[ord_].map(map_dict_ord)\n",
    "\n",
    "# convert categorical to binary\n",
    "bin_feats = ['Street', 'Utilities', 'CentralAir']\n",
    "map_dict_bin = {'Pave': 0, 'Grvl': 1, 'AllPub': 0, 'NoSeWa': 1, 'Y': 1, 'N': 0}\n",
    "for bin_ in bin_feats:\n",
    "    all_data[bin_] = all_data[bin_].map(map_dict_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalePrice    1459\n",
       "dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values\n",
    "# should only return SalePrice with 1459 missing values\n",
    "isnull = all_data.isnull().sum()\n",
    "isnull[isnull > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_ = all_data['Id']\n",
    "all_data.drop(columns='Id', inplace=True)\n",
    "target = all_data['SalePrice']\n",
    "all_data.drop(columns='SalePrice', inplace=True)\n",
    "num_feats = all_data.select_dtypes(exclude='object')\n",
    "cat_feats = all_data.select_dtypes('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2919,), (2919,), (2919, 50), (2919, 29), (2919, 79))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_.shape, target.shape, num_feats.shape, cat_feats.shape, all_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "- log transform target\n",
    "- add all square feet variables to find the total square feet of the house\n",
    "- transform highly skewed features with box cox\n",
    "    - we need to use boxcox1p, to account for the zeros in the dataset\n",
    "    - I will transform every numerical feature with a skeweness higher than 1 and below -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.log(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feats['TotalSF'] = num_feats['TotalBsmtSF'] + num_feats['1stFlrSF'] + num_feats['2ndFlrSF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get absloute skewness values for each num feature\n",
    "skew_feats_o = abs(num_feats.skew())\n",
    "# transform those with a skewness higher than 0.75\n",
    "skew_feats = skew_feats_o[skew_feats_o > 0.75]\n",
    "skew_list = list(skew_feats.index)\n",
    "# defina lambda, lambda of 0 is equvalent of log transformation\n",
    "lam = 0.15\n",
    "for feat in skew_list:\n",
    "    num_feats[feat] = boxcox1p(num_feats[feat], lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dummies for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy varibales\n",
    "dummy_feats = list(cat_feats)\n",
    "df_dummy = pd.get_dummies(all_data[dummy_feats], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([id_, target, num_feats, df_dummy], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with no predictive value\n",
    "final_df.drop(columns=['Utilities'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split all_data in train and test to perform more preprocessing and feature engineering speratly (prevent data leakage)\n",
    "train = final_df.loc[:train.shape[0]-1]\n",
    "test = final_df.loc[train.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rest index so that the index start at 0\n",
    "test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 242), (1459, 242))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers \n",
    "train = train.drop(train[(train['GrLivArea']>boxcox1p(4000, lam)) & (train['SalePrice']<np.log(300000))].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1458, 242), (1459, 242))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save id \n",
    "Id = test['Id']\n",
    "# drop id\n",
    "test.drop(columns='Id', inplace=True)\n",
    "train.drop(columns='Id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1458, 241), (1459, 241))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use train set to make x_train and y_train\n",
    "x_train = train.drop(columns=['SalePrice'])\n",
    "y_train = train['SalePrice']\n",
    "test.drop(columns='SalePrice', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1458, 240), (1458,), (1459, 240))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if x_train and test_pre are identical\n",
    "list(set(x_train) - set(test)), list(set(test) - set(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code: https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard\n",
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n",
    "    rmsle= np.sqrt(-cross_val_score(model, x_train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_xgb rmsle score:\n",
      "0.13334509338994802\n",
      "##############################\n",
      "model_lgb rmsle score:\n",
      "0.12704825791903968\n",
      "##############################\n",
      "model_cat rmsle score:\n",
      "0.11537198302846566\n",
      "##############################\n",
      "model_lasso rmsle score:\n",
      "0.2665729076443017\n",
      "##############################\n",
      "model_ridge rmsle score:\n",
      "0.11826202886295231\n",
      "##############################\n",
      "model_elnet rmsle score:\n",
      "0.2627933003105244\n",
      "##############################\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "model_xgb = XGBRegressor()\n",
    "# LightGBM\n",
    "model_lgb = LGBMRegressor()\n",
    "# CatBoost\n",
    "model_cat = CatBoostRegressor(verbose=False)\n",
    "# Lasso Regression\n",
    "model_lasso = Lasso(random_state=42)\n",
    "# Ridge Regression\n",
    "model_ridge = Ridge(random_state=42)\n",
    "# ElasticNet\n",
    "model_elnet = ElasticNet(random_state=42)\n",
    "\n",
    "# list of models for cross validation\n",
    "models_list = [model_xgb, model_lgb, model_cat, model_lasso, model_ridge, model_elnet]\n",
    "model_names = ['model_xgb', 'model_lgb', 'model_cat', 'model_lasso', 'model_ridge', 'model_elnet']\n",
    "\n",
    "for model, name in zip(models_list, model_names):\n",
    "    print(name + ' rmsle score:')\n",
    "    print(np.mean(rmsle_cv(model)))\n",
    "    print('#'*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is obvious that lasso and elasticnet perfomes suffers a lot from using box cox transformation. This is due to the different sacels of the numeric data, with some features tranformed and others in their original scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "> from looking at different Kaggle kernels there is a lot of predictive power in hyperparameter tuning for Lasso and Elastic Net Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Regression\n",
    "- alpha: constant that is multiplied with the L1 penalty regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  25 out of  25 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.001}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = Lasso(random_state=42)\n",
    "params = {'alpha': [1, 0.1, 0.01, 0.001, 0.00001]}\n",
    "\n",
    "gsc = GridSearchCV(estimator=estimator, param_grid=params, \n",
    "                   scoring='neg_mean_squared_error', \n",
    "                   verbose=1,\n",
    "                   n_jobs=-2)\n",
    "\n",
    "grid_result = gsc.fit(x_train, y_train)\n",
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11570958142263246"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rmsle_cv(Lasso(alpha=0.001, random_state=42)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> this is a huge improvement for the lasso regrssion from 0.26 to 0.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elastic Net Regression\n",
    "- alpha: constant that multiplies with the penalty terms (L1 and L2)\n",
    "- l1_ration: mixing parameter for L1 and L2 penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  75 out of  75 | elapsed:    6.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.001, 'l1_ratio': 0.2}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = ElasticNet(random_state=42)\n",
    "params = {'alpha': [1, 0.1, 0.01, 0.001, 0.00001],\n",
    "          'l1_ratio': [0.8, 0.5, 0.2]}\n",
    "\n",
    "gsc = GridSearchCV(estimator=estimator, param_grid=params, \n",
    "                   scoring='neg_mean_squared_error', \n",
    "                   verbose=1,\n",
    "                   n_jobs=-2)\n",
    "\n",
    "grid_result = gsc.fit(x_train, y_train)\n",
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11424849584553462"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rmsle_cv(ElasticNet(alpha=0.001, l1_ratio=0.2, random_state=42)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> also an huge improvement from 0.26 to 0.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blended Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>120104.758252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>157547.080419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>184268.693592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>198023.681177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>197433.793237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>85888.426262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>80874.355782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>171166.379830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>119164.251244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>224401.571208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id      SalePrice\n",
       "0     1461  120104.758252\n",
       "1     1462  157547.080419\n",
       "2     1463  184268.693592\n",
       "3     1464  198023.681177\n",
       "4     1465  197433.793237\n",
       "...    ...            ...\n",
       "1454  2915   85888.426262\n",
       "1455  2916   80874.355782\n",
       "1456  2917  171166.379830\n",
       "1457  2918  119164.251244\n",
       "1458  2919  224401.571208\n",
       "\n",
       "[1459 rows x 2 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define models\n",
    "model_ridge = Ridge(random_state=42)\n",
    "model_cat = CatBoostRegressor(verbose=False)\n",
    "model_lasso = Lasso(alpha=0.001, random_state=42)\n",
    "model_elnet = ElasticNet(alpha=0.001, l1_ratio=0.2, random_state=42)\n",
    "\n",
    "# train\n",
    "#model_xgb.fit(x_train, y_train)\n",
    "#model_lgb.fit(x_train, y_train)\n",
    "model_ridge.fit(x_train, y_train)\n",
    "model_cat.fit(x_train, y_train)\n",
    "model_lasso.fit(x_train, y_train)\n",
    "model_elnet.fit(x_train, y_train)\n",
    "\n",
    "# predict\n",
    "#xgb_preds = model_xgb.predict(test)\n",
    "#lgb_preds = model_lgb.predict(test)\n",
    "ridge_preds = model_ridge.predict(test)\n",
    "cat_preds = model_cat.predict(test)\n",
    "lasso_preds = model_lasso.predict(test)\n",
    "elnet_preds = model_elnet.predict(test)\n",
    "\n",
    "# calculate\n",
    "preds = (ridge_preds + cat_preds + lasso_preds + elnet_preds)/4\n",
    "\n",
    "# create DataFrame for submission\n",
    "submission = pd.DataFrame()\n",
    "submission['Id'] = Id\n",
    "# transform log of SalePrice\n",
    "submission['SalePrice'] = np.exp(preds)\n",
    "# save DataFrame\n",
    "submission.to_csv('blended_model_ht_1.csv', index=False)\n",
    "# show submission\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
